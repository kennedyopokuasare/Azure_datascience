{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run Experiments with Scripts with Azure Machine Learning Python SDK (v2)\n",
        "\n",
        "You can use the Python SDK for Azure Machine Learning to submit scripts as jobs. By using jobs, you can easily keep track of the input parameters and outputs when training a machine learning model.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the **azure.ai.ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure.ai.ml** package is not installed, run `pip install azure.ai.ml` to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.20.0\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: /opt/anaconda3/envs/automate/lib/python3.12/site-packages\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip show azure.ai.ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. A `config.json` file containing these parameters can be downloaded from the Azure Machine Learning workspace or Azure portal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: ../../config.json\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "ml_client = MLClient.from_config(credential= DefaultAzureCredential(), path=\"../../config.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the dataset\n",
        "\n",
        "Azure Machine Learning providers several datastores that encapsulates a Dataset. Be considerate about the kind of datastores, use cases, and associated costs to determine the best datasource. Here we use the default datasource which is `blob` data store.\n",
        "\n",
        "**Authenticate with `Azure CLI` is required here**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exception while registering dataset  (UserError) A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's data uri cannot be changed. Only tags, description, and isArchived can be updated.\n",
            "Code: UserError\n",
            "Message: A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's data uri cannot be changed. Only tags, description, and isArchived can be updated.\n",
            "Additional Information:Type: ComponentName\n",
            "Info: {\n",
            "    \"value\": \"managementfrontend\"\n",
            "}Type: Correlation\n",
            "Info: {\n",
            "    \"value\": {\n",
            "        \"operation\": \"ea58a3e20ff445203b9df2e7f582fb9e\",\n",
            "        \"request\": \"75ae9d9acc26925e\"\n",
            "    }\n",
            "}Type: Environment\n",
            "Info: {\n",
            "    \"value\": \"northeurope\"\n",
            "}Type: Location\n",
            "Info: {\n",
            "    \"value\": \"northeurope\"\n",
            "}Type: Time\n",
            "Info: {\n",
            "    \"value\": \"2024-09-14T14:13:03.8109689+00:00\"\n",
            "}Type: InnerError\n",
            "Info: {\n",
            "    \"value\": {\n",
            "        \"code\": \"Immutable\",\n",
            "        \"innerError\": {\n",
            "            \"code\": \"DataVersionPropertyImmutable\",\n",
            "            \"innerError\": null\n",
            "        }\n",
            "    }\n",
            "}Type: MessageFormat\n",
            "Info: {\n",
            "    \"value\": \"A data version with this name and version already exists. If you are trying to create a new data version, use a different name or version. If you are trying to update an existing data version, the existing asset's {property} cannot be changed. Only tags, description, and isArchived can be updated.\"\n",
            "}Type: MessageParameters\n",
            "Info: {\n",
            "    \"value\": {\n",
            "        \"property\": \"data uri\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "file = \"../../data/diabetes.csv\"\n",
        "\n",
        "diabetes_data = Data(\n",
        "    name=\"diabetes_csv\",\n",
        "    path=file,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Dataset for Diabetes model training\",\n",
        "    tags={\"source_type\": \"file\", \"source\": \"Local file\"},\n",
        "    version=\"1.0.0\",\n",
        ")\n",
        "\n",
        "try:\n",
        "    diabetes_data = ml_client.data.create_or_update(diabetes_data)\n",
        "except (Exception) as ex:  \n",
        "    print(\"Exception while registering dataset \", ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create the Python script to train and score a model\n",
        "\n",
        "To train a model, you'll first create the **diabetes_training.py** script in the **src** folder. The script uses the **diabetes.csv** data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/diabetes-training.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile src/diabetes-training.py\n",
        "# import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Parse job parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--reg-rate', type=float, dest='reg_rate', default=0.01)\n",
        "parser.add_argument('--test-size', type=float, dest='test_size', default=0.30)\n",
        "parser.add_argument('--data-set', type=str,dest=\"data\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "reg_rate = args.reg_rate\n",
        "test_size = args.test_size\n",
        "print(\"Test data size:\", test_size)\n",
        "print(\"Regularization rate:\", reg_rate)\n",
        "\n",
        "# load the diabetes dataset\n",
        "print(\"Loading Data...\")\n",
        "diabetes = pd.read_csv(args.data, header=0)\n",
        "\n",
        "print(\"num_samples:\", diabetes.shape[0])\n",
        "features = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']]\n",
        "print(\"num_features:\", features.shape[1])\n",
        "print(\"features:\", features.columns.values)\n",
        "\n",
        "# separate features and labels\n",
        "X = features.values\n",
        "y = diabetes['Diabetic'].values\n",
        "\n",
        "# split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
        "\n",
        "# train a logistic regression model\n",
        "print('Training a logistic regression model with regularization rate of', reg_rate)\n",
        "model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "# calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', float(acc))\n",
        "\n",
        "# calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "\n",
        "# Save the model to file\n",
        "print(\"Saving model to file\")\n",
        "filename = 'outputs/model.pkl'\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "with open(filename, 'wb') as file:\n",
        "    pickle.dump(model,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submit script to the run as Job\n",
        "\n",
        "Submit the script that trains a classification model to predict diabetes, to run on Azure ML. This will create a job base on the specifications of the command.\n",
        "\n",
        "The `enviroment` was created in Azure ML workspace, but can be created with a script\n",
        "\n",
        "Test data size (`test_size`) and Regularization rate (`reg_rate`) for the `LogisticRegression` are passed as parameters. Other parameters such as a registered dataset in a data store could also be passed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import command, Input\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "\n",
        "data_asset = ml_client.data.get(\"diabetes_csv\", version=\"1.0.0\")\n",
        "\n",
        "# Define arguments / parameters\n",
        "diabetes_data = ml_client.data.get(\"diabetes_csv\", version=\"1.0.0\")\n",
        "test_size = 0.30\n",
        "reg_rate = 0.01\n",
        "\n",
        "run_command = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python diabetes-training.py --data ${{inputs.data}} --test-size ${{inputs.test_size}} --reg-rate ${{inputs.reg_rate}} \",\n",
        "    inputs=dict(\n",
        "        data= Input(\n",
        "            path=diabetes_data.id,\n",
        "            type=AssetTypes.URI_FILE,\n",
        "            mode=InputOutputModes.RO_MOUNT,\n",
        "        ),\n",
        "        reg_rate = reg_rate,\n",
        "        test_size = test_size,\n",
        "    ),\n",
        "    environment=\"diabest-train:8\",\n",
        "    experiment_name = \"diabetes-training\"\n",
        ")\n",
        "\n",
        "returned_job = ml_client.jobs.create_or_update(run_command)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "automate",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
